# CLaRa Stage 3 - Gu√≠a de Instalaci√≥n y Configuraci√≥n

**Estado**: ‚úÖ **Instalaci√≥n completada y verificada** (11 Dic 2025)

> **Nota**: Este proyecto ya est√° completamente instalado en `/home/jose/Repositorios/ml-clara/`. Sigue los comandos de abajo para usar el modelo.

---

## üöÄ Inicio R√°pido (30 segundos)

```bash
# 1. Activar el ambiente
source /opt/miniconda3/etc/profile.d/conda.sh
conda activate clara
cd /home/jose/Repositorios/ml-clara

# 2. Ejecutar demo
python demo_clara.py

# 3. Ver documentaci√≥n
cat USO_RAPIDO.md
```

---

## üìã Documentaci√≥n Disponible

| Documento | Contenido |
|-----------|----------|
| **INSTALACION_COMPLETA.md** | Reporte exhaustivo de instalaci√≥n, problemas solucionados, test de verificaci√≥n |
| **USO_RAPIDO.md** | Gu√≠a pr√°ctica con ejemplos de c√≥digo para usar el modelo |
| **TROUBLESHOOTING.md** | Soluci√≥n a 15+ problemas comunes |
| **README.md** | Documentaci√≥n original del proyecto Apple CLaRa |

---

## üì¶ Lo que Est√° Instalado

### Modelos
- ‚úÖ **CLaRa-7B-E2E**: 745 MB descargado y verificado
- ‚úÖ **Mistral-7B-Instruct-v0.2**: 14 GB descargado y verificado

### Dependencias
- ‚úÖ **PyTorch**: 2.2.0 con CUDA 12.1
- ‚úÖ **Transformers**: 4.57.3
- ‚úÖ **PEFT**: 0.18.0
- ‚úÖ **+50 paquetes**: Todas las dependencias resueltas

### Ambiente Conda
- ‚úÖ **Conda**: v25.9.1 en `/opt/miniconda3`
- ‚úÖ **Ambiente "clara"**: Python 3.10.19, completamente funcional

---

## ‚úÖ Test de Verificaci√≥n

Se realiz√≥ test exitoso el **11 de Diciembre 2025, 03:21 UTC**:

```
Pregunta: "Where is Apple headquartered and who founded it?"

Documentos (5):
  1. Fundaci√≥n de Apple
  2. Dise√±o Apple I
  3. Sede de Apple        ‚Üê Seleccionado
  4. Productos Apple
  5. CEO Tim Cook         ‚Üê Seleccionado

Respuesta Generada:
  "Apple is headquartered in Cupertino, California,
   and was founded by Steve Jobs, Steve Wozniak,
   and Ronald Wayne."

‚úÖ RESULTADO: Correcto y coherente
```

**Detalles completos**: Ver secci√≥n 4 en `INSTALACION_COMPLETA.md`

---

## üíª Ejemplo B√°sico en Python

```python
from transformers import AutoModel
import torch

# Cargar modelo
model = AutoModel.from_pretrained(
    "./models/clara-e2e/compression-128",
    trust_remote_code=True
).to('cuda')

# Documentos
documents = [[
    "Apple fue fundada el 1 de abril de 1976 por Steve Jobs.",
    "La sede est√° ubicada en Cupertino, California.",
    "CEO es Tim Cook desde 2011."
]]

# Pregunta
questions = ["¬øD√≥nde est√° Apple y qui√©n la fund√≥?"]

# Generar respuesta
output, indices = model.generate_from_questions(
    questions=questions,
    documents=documents,
    max_new_tokens=64
)

print(output[0])      # Respuesta
print(indices[0])     # Docs seleccionados
```

---

## üîß Problemas Solucionados Durante Instalaci√≥n

| Problema | Soluci√≥n |
|----------|----------|
| pytorch-triton-rocm no existe | Removido (no necesario) |
| torch 2.8.0+cu118 inv√°lido | Cambiar a 2.2.0 |
| torchvision incompatible | Downgrade a 0.17.0 |
| fastapi/starlette conflicto | Removidos |
| **numpy 2.2.6 rompe PyTorch** | **Downgrade a numpy<2** |
| **PEFT incompatible** | **Transformers 4.57.3** |
| **config.json paths hardcoded** | **HuggingFace IDs** |

**Ver detalles**: Secci√≥n 2 en `INSTALACION_COMPLETA.md`

---

## üóÇÔ∏è Estructura del Repositorio

```
/home/jose/Repositorios/ml-clara/
‚îú‚îÄ‚îÄ models/clara-e2e/
‚îÇ   ‚îú‚îÄ‚îÄ compression-128/          ‚Üê MODELO PRINCIPAL (745 MB)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.json           (‚úÖ Corregido)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adapters.pth
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ decoder_first_last_layers.pth
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.model
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modeling_clara.py
‚îÇ   ‚îî‚îÄ‚îÄ compression-16/           (Alternativa)
‚îú‚îÄ‚îÄ scripts/                      (Entrenamiento)
‚îú‚îÄ‚îÄ evaluation/                   (Evaluaci√≥n)
‚îú‚îÄ‚îÄ example/                      (Datos ejemplo)
‚îú‚îÄ‚îÄ requirements-minimal.txt      (‚úÖ Versiones resueltas)
‚îú‚îÄ‚îÄ demo_clara.py                 (‚úÖ Demo funcional)
‚îú‚îÄ‚îÄ INSTALACION_COMPLETA.md      (Este proceso)
‚îú‚îÄ‚îÄ USO_RAPIDO.md                (Gu√≠a usuario)
‚îú‚îÄ‚îÄ TROUBLESHOOTING.md           (Soluci√≥n problemas)
‚îî‚îÄ‚îÄ README.md                    (Original Apple)
```

---

## üñ•Ô∏è Sistema

| Aspecto | Especificaci√≥n |
|---------|----------------|
| **GPU** | NVIDIA RTX 3090 (25.3 GB VRAM) |
| **CPU** | AMD Ryzen (m√∫ltiples n√∫cleos) |
| **RAM** | 32+ GB |
| **OS** | Ubuntu 24.04 LTS |
| **Almacenamiento usado** | ~31.5 GB (modelos + dependencias) |

---

## üìñ Pr√≥ximos Pasos

### Para Usar el Modelo
1. Lee `USO_RAPIDO.md` para ejemplos pr√°cticos
2. Ejecuta `python demo_clara.py` para verificar
3. Adapta los ejemplos a tus datos

### Si Hay Problemas
1. Consulta `TROUBLESHOOTING.md`
2. Revisa `INSTALACION_COMPLETA.md` para contexto t√©cnico
3. Verifica `requirements-minimal.txt` para dependencias

### Para Entrenar
1. Ver `scripts/` para scripts de training
2. Consultar `evaluation/` para benchmarks
3. Usar datos en `example/`

---

## üîó Referencias

- **Paper**: https://arxiv.org/abs/2511.18659
- **Modelos HuggingFace**: https://huggingface.co/apple/CLaRa-7B-E2E
- **GitHub Original**: https://github.com/apple/CLaRa

---

## ‚ùì Preguntas Frecuentes

**P: ¬øD√≥nde est√°n los archivos de documentaci√≥n?**
R: Todo est√° en este directorio (`/home/jose/Repositorios/ml-clara/`):
   - `INSTALACION_COMPLETA.md` - Proceso completo
   - `USO_RAPIDO.md` - C√≥mo usar el modelo
   - `TROUBLESHOOTING.md` - Solucionar problemas

**P: ¬øNecesito reinstalar?**
R: No. Todo est√° preconfigurado. Solo activa el ambiente conda:
   ```bash
   source /opt/miniconda3/etc/profile.d/conda.sh
   conda activate clara
   ```

**P: ¬øCu√°nto espacio necesita?**
R: ~31.5 GB total (modelos 15GB + dependencias 2.5GB + cach√© 14GB)

**P: ¬øQu√© GPU necesito?**
R: M√≠nimo 8GB VRAM. La RTX 3090 (25GB) tiene mucho headroom.

**P: ¬øPuedo usar CPU en lugar de GPU?**
R: S√≠, pero ser√° ~100x m√°s lento. Ver `USO_RAPIDO.md` ejemplo 3.

---

## üìä Benchmarks

Desempe√±o esperado del modelo:

| Dataset | Exactitud (CR=4, 128x) |
|---------|------------------------|
| NQ | 57.05% |
| HotpotQA | 45.09% |
| MuSiQue | 10.34% |
| 2Wiki | 46.94% |

**Velocidad** (RTX 3090): 150-200 tokens/segundo

---

**Instalaci√≥n completada**: 11 de Diciembre 2025, 03:21 UTC
**Estado**: ‚úÖ **OPERATIVO Y VERIFICADO**
**Pr√≥ximo paso**: Leer `USO_RAPIDO.md` o ejecutar `python demo_clara.py`
